{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4yd7PZLmA-Q"
   },
   "source": [
    "### Notwendige Module importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7aliz7QsmA-S",
    "outputId": "be0a69d7-a91d-4d46-c78d-a9f648d0e8bc"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m clear_output\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "import itertools\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "\n",
    "# Umschalten zwischen Colab oder lokaler Installation\n",
    "USING_COLAB = False\n",
    "\n",
    "if USING_COLAB:\n",
    "  from google.colab import drive\n",
    "  from google.colab.patches import cv2_imshow\n",
    "  drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a99GyVXJmA-T"
   },
   "source": [
    "### Definition von Konstanten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLEORkKRmA-U"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-2\n",
    "epochs = 40\n",
    "bTrainModel = True\n",
    "\n",
    "\n",
    "if USING_COLAB:\n",
    "  filenameModel = '/content/drive/My Drive/THK/ColabNotebooks/results/modelMNIST.pth'\n",
    "else:\n",
    "  filenameModel = 'results/modelMNIST.pth'\n",
    "\n",
    "if USING_COLAB:\n",
    "  pathImages = '/content/drive/My Drive/THK/ColabNotebooks/data/MNIST/images'\n",
    "else:\n",
    "  pathImages = 'data/MNIST/images'\n",
    "\n",
    "if USING_COLAB:\n",
    "  pathHackedImages = '/content/drive/My Drive/THK/ColabNotebooks/data/MNIST/hackedImages'\n",
    "else:\n",
    "  pathHackedImages = 'data/MNIST/hackedImages'\n",
    "\n",
    "if USING_COLAB:\n",
    "  pathStore = '/content/drive/My Drive/THK/ColabNotebooks/data/MNIST/adversarialImages'\n",
    "else:\n",
    "  pathStore = 'data/MNIST/adversarialImages'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKX_iqlemA-U"
   },
   "source": [
    "### Laden des Datensatzes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tclUdWURmA-U"
   },
   "source": [
    "##### Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCtibcHHmA-V",
    "outputId": "19dedd6e-683d-40f8-bb88-558afa026864"
   },
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.MNIST('data/', download=True, train=True)\n",
    "train_images = train_set.data\n",
    "train_targets = train_set.targets\n",
    "print(f\"Dataset images shape: \\t{train_images.shape}\")\n",
    "print(f\"Dataset labels shape: \\t{train_targets.shape}\")\n",
    "print(f\"Label classes: \\t\\t{train_targets.unique()}\")\n",
    "print(f\"Pixel values from \\t{train_images.min().numpy()} to {train_images.max().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2q1YCy_vmA-V"
   },
   "source": [
    "##### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZBarP_wmA-V",
    "outputId": "82dd4358-cafa-44f8-b3ac-c2535315edb0"
   },
   "outputs": [],
   "source": [
    "test_set = torchvision.datasets.MNIST('data/', download=True, train=False)\n",
    "test_images = test_set.data\n",
    "test_targets = test_set.targets\n",
    "print(f\"Dataset images shape: \\t{test_images.shape}\")\n",
    "print(f\"Dataset labels shape: \\t{test_targets.shape}\")\n",
    "print(f\"Label classes: \\t\\t{test_targets.unique()}\")\n",
    "print(f\"Pixel values from \\t{test_images.min().numpy()} to {test_images.max().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfUQN8KWmA-W"
   },
   "source": [
    "### Erstellen nötiger Klassen und Funktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFuaAWjHmA-X"
   },
   "source": [
    "##### MNISTDataset klasse für einfachere Handhabung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8IaZKCBmA-X"
   },
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        x = x.float()/255\n",
    "        x = x.unsqueeze(1)\n",
    "        self.x, self.y = x.cpu(), y.cpu()\n",
    "                 \n",
    "    def __getitem__(self, ix):\n",
    "        x, y = self.x[ix], self.y[ix]\n",
    "        return x.to(device), y.to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def append(self, newX, newY):\n",
    "        self.x = torch.cat([self.x, newX], dim=0)\n",
    "        self.y = torch.cat([self.y, newY], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdJAYHGymA-X"
   },
   "source": [
    "##### Funktion zum aufteilen des Train-Dataset in train und validate data und erzeugen der DataLoader für späteres Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOA2zzyumA-X"
   },
   "outputs": [],
   "source": [
    "def get_data(train_images, train_targets, test_images, test_targets):\n",
    "  train_indices, val_indices, _, _ = train_test_split(range(len(train_images)), train_targets, test_size=0.2, stratify=train_targets)\n",
    "\n",
    "  imagesToTrain = []\n",
    "  targetsToTrain = []\n",
    "\n",
    "  for idx in train_indices:\n",
    "    imagesToTrain.append(train_images[idx])\n",
    "    targetsToTrain.append(train_targets[idx])\n",
    "  \n",
    "  imagesToTrainTensor = torch.stack(imagesToTrain, dim=0)\n",
    "  targetsToTrainTensor = torch.stack(targetsToTrain, dim=0)\n",
    "\n",
    "  train_ds = MNISTDataset(imagesToTrainTensor, targetsToTrainTensor)\n",
    "  train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "  imagesToValidation = []\n",
    "  targetsToValidation = []\n",
    "\n",
    "  for idx in val_indices:\n",
    "    imagesToValidation.append(train_images[idx])\n",
    "    targetsToValidation.append(train_targets[idx])\n",
    "  \n",
    "  imagesToValidationTensor = torch.stack(imagesToValidation, dim=0)\n",
    "  targetsToValidationTensor = torch.stack(targetsToValidation, dim=0)\n",
    "\n",
    "  validate_ds = MNISTDataset(imagesToValidationTensor, targetsToValidationTensor)\n",
    "  validate_dl = DataLoader(validate_ds, batch_size=len(targetsToValidationTensor), shuffle=False)\n",
    "\n",
    "  test_ds = MNISTDataset(test_images, test_targets)\n",
    "  test_dl = DataLoader(test_ds, batch_size=len(test_images), shuffle=False)\n",
    "  \n",
    "  return train_ds, train_dl, test_ds, test_dl, validate_ds, validate_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6MRUYm-mA-X"
   },
   "source": [
    "##### Erzeugen des models inklusive Convolutional Neural Network, Optimizer und Loss-Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-kDS06QmA-Y"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 10, kernel_size=5),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(10, 20, kernel_size=5),\n",
    "        nn.Dropout2d(0.5),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(320, 50),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(50 ,10)\n",
    "    ).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), momentum=0.5, lr=LEARNING_RATE)\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qUTHrEBmA-Y"
   },
   "source": [
    "##### Funktion zum Trainieren mit einem Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bC8INnLjmA-Y"
   },
   "outputs": [],
   "source": [
    "def train_batch(x, y, model, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    prediction = model(x)\n",
    "    batch_loss = loss_fn(prediction, y)\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return batch_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klCxV9h2mA-Y"
   },
   "source": [
    "##### Funktion zum berechnen der Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-64Ko6sCmA-Y"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def accuracy(x, y, model):\n",
    "  with torch.no_grad():\n",
    "    prediction = model(x)\n",
    "  max_values, argmaxes = prediction.max(-1)\n",
    "  is_correct = argmaxes == y\n",
    "  return is_correct.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTn7KJOBmA-Y"
   },
   "source": [
    "##### Funktion zum Berechnen dess Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swtFobtGmA-Z"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def loss(x, y, model, loss_fn):\n",
    "  with torch.no_grad():\n",
    "    prediction = model(x)\n",
    "    loss = loss_fn(prediction, y)\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJHvTc-PmA-Z"
   },
   "source": [
    "### Erzeugen von DataLoader und Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rmzzb5swmA-Z"
   },
   "outputs": [],
   "source": [
    "train_ds, train_dl, test_ds, test_dl, validate_ds, validate_dl = get_data(train_images, train_targets, test_images, test_targets)\n",
    "model, loss_fn, optimizer = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHn3EAfVmA-Z"
   },
   "source": [
    "### Plotten der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iEBY0rCemA-Z"
   },
   "outputs": [],
   "source": [
    "def plot_evals(train_loss, val_loss, train_acc, val_acc, store=None):\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss, label=\"train_loss\")\n",
    "    plt.plot(val_loss, label=\"val_loss\")\n",
    "    plt.plot(train_acc, label=\"train_acc\")\n",
    "    plt.plot(val_acc, label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    if store is not None:\n",
    "        plt.savefig(store)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdxsknTvmA-Z"
   },
   "source": [
    "### Trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZfXdGcHmA-Z"
   },
   "outputs": [],
   "source": [
    "def trainModel(model, train_dl, validate_dl, test_dl, epochs):\n",
    "  #Train\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  epoch_loss = []\n",
    "  train_acc_epoch = []\n",
    "\n",
    "  val_epoch_loss = []\n",
    "  val_acc_epoch = []\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "      start = time.time()\n",
    "      loss_each_batch = []\n",
    "      acc_each_batch = []\n",
    "\n",
    "      #Model trainieren\n",
    "      for x, y in tqdm(train_dl):\n",
    "          x = x.to(device)\n",
    "          y = y.to(device)\n",
    "          #tepoch.set_description(f\"Epoch {epoch}\")\n",
    "          batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
    "          loss_each_batch.append(batch_loss)\n",
    "\n",
    "      epoch_loss.append(np.array(loss_each_batch).mean())\n",
    "      train_acc_batch = []\n",
    "\n",
    "      #Evaluation auf Train Dataset\n",
    "      for i, batch in enumerate(iter(train_dl)):\n",
    "          x, y = batch\n",
    "          is_correct = accuracy(x, y, model)\n",
    "          train_acc_batch.extend(is_correct)\n",
    "      train_acc_epoch.append(np.mean(train_acc_batch))\n",
    "\n",
    "      val_acc_batch = []\n",
    "      val_loss_batch = []\n",
    "\n",
    "      #Evaluation auf Validation Dataset\n",
    "      for i, batch in enumerate(iter(validate_dl)):\n",
    "          x, y = batch\n",
    "          is_correct = accuracy(x, y, model)\n",
    "          val_acc_batch.extend(is_correct)\n",
    "          val_loss = loss(x, y, model, loss_fn)\n",
    "          val_loss_batch.append(val_loss)\n",
    "      val_epoch_loss.append(np.array(val_loss_batch).mean())\n",
    "      val_acc_epoch.append(np.array(val_acc_batch).mean())\n",
    "\n",
    "      print(f\"Epoch {epoch+1}/{epochs}:\\taccTrain: {100. * train_acc_epoch[-1]:.2f}\\taccVal: {100. * val_acc_epoch[-1]:.2f}\\tloss: {epoch_loss[-1]:.2f}\\ttime: {time.time()-start:.2f}\")\n",
    "\n",
    "  # Testen auf Test-Dataset\n",
    "  test_acc = []\n",
    "  testRes = 0\n",
    "  for i, batch in enumerate(iter(test_dl)):\n",
    "    x, y = batch\n",
    "    is_correct = accuracy(x, y, model)\n",
    "    test_acc.extend(is_correct)\n",
    "    testRes = np.array(test_acc).mean()\n",
    "  print( f\"testRes {100. * testRes:.2f}\" )\n",
    "    \n",
    "  plot_evals(epoch_loss, val_epoch_loss, train_acc_epoch, val_acc_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hcq4iBNDmA-a"
   },
   "outputs": [],
   "source": [
    "if bTrainModel:\n",
    "    trainModel(model, train_dl, validate_dl, test_dl,  epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GonKS52nmA-a"
   },
   "source": [
    "### Speichern/Laden von Model und Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L77FVExWmA-a"
   },
   "outputs": [],
   "source": [
    "if bTrainModel:\n",
    "  torch.save(model.state_dict(), filenameModel)\n",
    "  #torch.save(optimizer.state_dict(), 'results/optimizer.pth')\n",
    "else:\n",
    "  model.load_state_dict(torch.load(filenameModel))\n",
    "  model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kw-FbXoVmA-a"
   },
   "source": [
    "### Funktion zum Erzeugen von Adversarial Images mit Rauschen, MNIST-Bild oder leerem Bild als initiales Bild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJaKOO6WmA-a"
   },
   "source": [
    "#### Mit learning rate spielen!\n",
    "- 1e-2 ist gut für das Hinzufügen von vielen adversarial images zum Datensatz, da Geschwindigkeit höher\n",
    "- 1e-4 ist gut um adversarial images zu erzeugen, welche sehr nah am Original sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ddlrGW-4wnq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_adversarial(from_number: int, to_predict: int, display=False, store=False) -> torch.Tensor:\n",
    "\n",
    "    #model.eval()\n",
    "        \n",
    "    pathOutput = pathStore + '/noise/'\n",
    "\n",
    "    if 0 <= from_number <= 9:\n",
    "        pathOutput = pathStore + '/' + str(from_number) + '/'\n",
    "        # Zufälliges initiales Bild aus from_number Klasse holen\n",
    "        indices = [i for i, y in enumerate(train_ds.y) if y == from_number]\n",
    "        rndIdx = random.choice(indices)\n",
    "        adversarial_sample, adversarial_target = train_ds[rndIdx]\n",
    "        adversarial_sample = adversarial_sample.unsqueeze(0)\n",
    "        #Bei Bedarf Rauschen hinzufügen\n",
    "        #noise = torch.rand((1, 1, 28, 28)).requires_grad_()\n",
    "        #adversarial_sample.data += 0.1 * noise.data\n",
    "    else:\n",
    "        adversarial_sample = torch.rand(1, 1, 28, 28)  # Werte hier gleichverteilt in [0, 1]\n",
    "        adversarial_sample = adversarial_sample.to(device)\n",
    "\n",
    "    # Create directories if they don't exist yet\n",
    "    if store:\n",
    "        if not os.path.exists(pathStore):\n",
    "            os.makedirs(pathStore)\n",
    "        if not os.path.exists(pathOutput):\n",
    "            os.makedirs(pathOutput)\n",
    "\n",
    "    # Label-Tensor erzeugen\n",
    "    targeted_adversarial_class = torch.tensor([to_predict]).to(device)\n",
    "\n",
    "    # Initiales Bild plotten\n",
    "    if display:\n",
    "        plt.imshow(adversarial_sample.cpu().data.view(28, 28), cmap='gray')\n",
    "        plt.grid(False)\n",
    "        plt.show()\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Optimizer für Gradientenabstieg erzeugen\n",
    "    adversarial_optimizer = torch.optim.SGD([adversarial_sample.requires_grad()], lr=1e-3)\n",
    "\n",
    "    # History initialisieren\n",
    "    losses = []\n",
    "\n",
    "    for i in range(50000):\n",
    "        #Gradienten zurücksetzen\n",
    "        adversarial_optimizer.zero_grad()\n",
    "\n",
    "        #Model predicten lassen\n",
    "        prediction = model(adversarial_sample)\n",
    "\n",
    "        #Loss berechnen und zu History hinzufügen\n",
    "        adv_loss = nn.CrossEntropyLoss()(prediction, targeted_adversarial_class)\n",
    "        losses.append(adv_loss.cpu().detach().numpy())\n",
    "\n",
    "        #Die Predicted Class aus prediction auswerten\n",
    "        predicted_class = np.argmax(prediction.cpu().detach().numpy(), axis=1)\n",
    "\n",
    "        #Falls gewünschte Klasse predicted wurde, stoppen\n",
    "        if predicted_class == to_predict:\n",
    "            if display:\n",
    "                clear_output(wait=True)\n",
    "                plt.imshow(adversarial_sample.cpu().data.view(28, 28), cmap='gray')\n",
    "                plt.grid(False)\n",
    "                plt.show()     \n",
    "\n",
    "                print( f\"!! Predicted: {predicted_class[0]}\" )\n",
    "                print( f\"!! Model output: {prediction.detach().cpu().numpy()}\" )\n",
    "                print( f\"!! Loss: {adv_loss.data}\" )\n",
    "\n",
    "            if store:\n",
    "                num_files = len(os.listdir(pathOutput))\n",
    "                img_path = os.path.join(pathOutput, str(num_files)+\".png\")\n",
    "                cv2.imwrite(img_path, (adversarial_sample.cpu().data.numpy()*255).reshape((28, 28)))\n",
    "\n",
    "            return adversarial_sample\n",
    "\n",
    "        # Backward propagation und Gradientenabstieg ausführen\n",
    "        adv_loss.backward()\n",
    "        adversarial_optimizer.step()\n",
    "\n",
    "        # Clipping des Adversarial Images zwischen 0 und 1\n",
    "        adversarial_sample.data = torch.clamp(adversarial_sample.data, 0, 1).to(device)\n",
    "\n",
    "        # Darstellung des Adversarial Images nach 500 steps\n",
    "        if display and i % 500 == 0:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            plt.imshow(adversarial_sample.data.cpu().view(28, 28), cmap='gray')\n",
    "            plt.grid(False)\n",
    "            plt.show()\n",
    "\n",
    "            print( f\"Predicted: {predicted_class[0]}\" )\n",
    "            print( f\"Model output: {prediction.detach().cpu().numpy()}\" )\n",
    "            print('Loss:', np.average(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98ZVc4tR_Fzr",
    "outputId": "5071365f-9e56-4593-d4de-afd289bf1cac"
   },
   "outputs": [],
   "source": [
    "#Adversarial Image testweise erzeugen\n",
    "adversarial_sample = createAdversarial(0, 4, display=True, store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, j) in permutations(zip(range(10), range(10))):\n",
    "        adversarial_sample = create_adversarial(i, j, display=True, store=True)\n",
    "        adversarials[i].append(adversarial_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TYXSK20JmA-b",
    "outputId": "092371e6-0cc5-45d7-e4e0-c45953b47f11"
   },
   "outputs": [],
   "source": [
    "# 20 Adversarial Images pro Klasse erzeugen\n",
    "for i, j in tqdm(itertools.product(range(10), range(20))):\n",
    "  originalClass = i\n",
    "  targetClass = -1\n",
    "  while targetClass < 0:\n",
    "    rnd = np.random.randint(10)\n",
    "    if rnd != originalClass:\n",
    "      targetClass=rnd\n",
    "\n",
    "  print( f\"original class {originalClass}  target class {targetClass}\" )\n",
    "\n",
    "  adv = createAdversarial(originalClass, targetClass, display=False, store=True)\n",
    "  advY = torch.tensor([originalClass])\n",
    "\n",
    "  if None==adv:\n",
    "    print(\"---\")\n",
    "  else:\n",
    "    print(\"+++\")\n",
    "    #adv = adv.cpu()\n",
    "    #train_ds.append( adv.cpu(), advY )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Igcn8qeHgdLZ"
   },
   "outputs": [],
   "source": [
    "def printDataSetInfo( ds ):\n",
    "  print( f\"#samples: {len(ds)}\" )\n",
    "  #print( f\"first elem: {ds[0]}\" )\n",
    "  print( f\"first x shape: {ds[0][0].shape}\" )  # Modify according to your data structure\n",
    "  print( f\"first y: {ds[0][1]}\" )  # Modify according to your data structure\n",
    "  print( f\"last x shape: {ds[-1][0].shape}\" )  # Modify according to your data structure\n",
    "  print( f\"last y: {ds[-1][1]}\" )  # Modify according to your data structure\n",
    "\n",
    "  class_counts = [0] * 10\n",
    "\n",
    "  # Iterate over the dataset and count examples per class\n",
    "  for _, label in ds:\n",
    "      class_counts[label] += 1\n",
    "\n",
    "  # Print the number of examples per class\n",
    "  for class_label, count in enumerate(class_counts):\n",
    "      print(f\"Class {class_label}: {count} examples\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
