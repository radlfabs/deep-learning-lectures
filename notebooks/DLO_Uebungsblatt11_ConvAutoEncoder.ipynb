{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PacktPublishing/Hands-On-Computer-Vision-with-PyTorch/blob/master/Chapter11/conv_auto_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tiKu4yccpwh"
   },
   "source": [
    "## Quelle: V Kishore Ayyadevara and Yeshwanth Reddy, Modern Computer Vision with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ih79PVHDOBbP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print( f\"device: {device}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "114BXPdocpwi"
   },
   "outputs": [],
   "source": [
    "img_transform =  torchvision.transforms.Compose([\n",
    "     torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize([0.5], [0.5]),\n",
    "     torchvision.transforms.Lambda(lambda x: x.to(device))\n",
    "])\n",
    "\n",
    "trn_ds = torchvision.datasets.MNIST('data/', transform=img_transform, train=True, download=True)\n",
    "test_ds = torchvision.datasets.MNIST('data/', transform=img_transform, train=False, download=True)\n",
    "\n",
    "batch_size = 32\n",
    "trn_dl = DataLoader(trn_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mpVWMJrODZT",
    "outputId": "c3bfa067-8d0d-4941-cb1b-17397bb80de0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ConvAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=3, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(32, 16, 5, stride=3, padding=1), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 1, 2, stride=2, padding=1), nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "achT19GPOnna"
   },
   "outputs": [],
   "source": [
    "def train_batch(input, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input)\n",
    "    loss = criterion(output, input)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2uBFRA7fOxEy"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_batch(input, model, criterion):\n",
    "    model.eval()\n",
    "    output = model(input)\n",
    "    loss = criterion(output, input)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ts0Y3r3IOyB_"
   },
   "outputs": [],
   "source": [
    "model = ConvAutoEncoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gs272A_cOzY8",
    "outputId": "52579d29-26aa-4df6-d9e2-f9ef79655d8d"
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    N = len(trn_dl)\n",
    "    lossTrainSum = 0\n",
    "    for ix, (data, _) in enumerate(trn_dl):\n",
    "        loss = train_batch(data, model, criterion, optimizer)\n",
    "        lossTrainSum += loss\n",
    "        \n",
    "    M = len(test_dl)\n",
    "    lossTestSum = 0\n",
    "    for ix, (data, _) in enumerate(test_dl):\n",
    "        loss = validate_batch(data, model, criterion)\n",
    "        lossTestSum += loss\n",
    "\n",
    "    print( f\"epoch {epoch}  loss train {lossTrainSum/len(trn_dl)}  loss test {lossTestSum/len(test_dl)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQe2HKx7cpwk"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"convAutoEncoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQe828B9cpwk"
   },
   "outputs": [],
   "source": [
    "def plotImages( img1, img2 ):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow( img1, cmap='gray' )\n",
    "    ax[0].set_title('input')\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow( img2, cmap='gray' )\n",
    "    ax[1].set_title('prediction')\n",
    "    ax[1].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wzRr6JAcpwl"
   },
   "source": [
    "## Zuf채lliges Bild aus dem Trainingsdatensatz kodieren-->dekodieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dOUhfD7Jcpwl",
    "outputId": "268b5205-fe89-4b93-9b20-00630c5648f2"
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    ix = np.random.randint(len(trn_ds))\n",
    "    im, _ = trn_ds[ix]\n",
    "    _im = model(im[None])[0] # durch das [None] wird dem Bild-Tensor \"im\" (1x28x28) eine Extra-Dimension hinzugef체gt\n",
    "    plotImages( im[0].cpu().detach().numpy(), _im[0].cpu().detach().numpy() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NQRNJh8cpwl"
   },
   "source": [
    "## Zuf채lliges Bild aus dem Testdatensatz kodieren-->dekodieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "nk5sw_t2PkDp",
    "outputId": "70a94c70-d755-48b3-f551-ae0d6487f46b"
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    ix = np.random.randint(len(test_ds))\n",
    "    im, _ = test_ds[ix]\n",
    "    _im = model(im[None])[0] # durch das [None] wird dem Bild-Tensor \"im\" (1x28x28) eine Extra-Dimension hinzugef체gt\n",
    "    plotImages( im[0].cpu().detach().numpy(), _im[0].cpu().detach().numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salt_and_pepper_noise(x):\n",
    "    \"\"\"adds salt and pepper noise to a (28, 28) tensor\"\"\"\n",
    "    x = x.clone()\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            if random.random() < 0.05:\n",
    "                x[0, i, j] = 1.0\n",
    "            elif random.random() > 0.95:\n",
    "                x[0, i, j] = 0.0\n",
    "    return x\n",
    "    \n",
    "    \n",
    "# get a random image from the train set and add noise\n",
    "ix = np.random.randint(len(trn_ds))\n",
    "im, _ = trn_ds[ix]\n",
    "im_noise = salt_and_pepper_noise(im)\n",
    "# from (1, 28, 28) to (28, 28)\n",
    "im_noise    = im_noise[0].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean vector over training images in latent space\n",
    "# call model.encoder(x) in loop and take mean of output\n",
    "# use model.encoder(x).cpu().detach().numpy() to get numpy array\n",
    "# use np.mean( ... , axis=0 ) to get mean vector\n",
    "\n",
    "# for every class in the training set, compute the mean vector in the latent space\n",
    "# use model.encoder(x).cpu().detach().numpy() to get numpy array\n",
    "# use np.mean( ... , axis=0 ) to get mean vector\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_latent_batch(input, model):\n",
    "    model.eval()\n",
    "    output = model.encoder(input)\n",
    "    return output\n",
    "\n",
    "outputs = []\n",
    "for ix, (data, _) in enumerate(trn_dl):\n",
    "    output = get_latent_batch(data, model)\n",
    "    output = output.cpu().detach().numpy()\n",
    "    outputs.append(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def decode(input, model):\n",
    "    model.eval()\n",
    "    output = model.decoder(input)\n",
    "    return output\n",
    "\n",
    "fig, ax = plt.subplots(1, 10)\n",
    "for i in range(10):\n",
    "    # outputs is a numpy array -> make it a tensor\n",
    "    im_tensor = torch.tensor(outputs[i])\n",
    "    im = outputs[i].to(device)\n",
    "    decoded = decode(im, model)\n",
    "    ax[i].imshow(decoded, cmap='gray' )\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_latent_batch(input, model):\n",
    "    model.eval()\n",
    "    output = model.encoder(input)\n",
    "    return output\n",
    "\n",
    "outputs = []\n",
    "for digit in range(10):\n",
    "    digit_outputs = []\n",
    "    for ix, (data, labels) in enumerate(trn_dl):\n",
    "        mask = labels == digit\n",
    "        if not mask.any():\n",
    "            continue\n",
    "        output = get_latent_batch(data[mask], model)\n",
    "        output = output.cpu().detach().numpy()\n",
    "        digit_outputs.append(output)\n",
    "    digit_outputs = np.concatenate(digit_outputs, axis=0)\n",
    "    mean_vector = np.mean(digit_outputs, axis=0)\n",
    "    outputs.append(mean_vector)\n",
    "outputs = np.stack(outputs, axis=0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def decode(input, model):\n",
    "    model.eval()\n",
    "    output = model.decoder(input)\n",
    "    return output\n",
    "\n",
    "fig, ax = plt.subplots(1, 10)\n",
    "for i in range(10):\n",
    "    im_tensor = torch.tensor(outputs[i]).to(device)\n",
    "    decoded = decode(im_tensor, model)\n",
    "    ax[i].imshow(decoded[0].cpu().detach().numpy(), cmap='gray' )\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "# choose two digits and move in latent space from one mean vector to the other\n",
    "# use torch.linspace to create a vector of 10 points between the two mean vectors\n",
    "# use torch.stack to create a tensor of shape (10, 10) from the 10 vectors\n",
    "# use model.decoder to decode the 10 vectors\n",
    "# use torchvision.utils.make_grid to create a grid of the 10 images\n",
    "# use plt.imshow to plot the grid\n",
    "\n",
    "digits = [0, 8]\n",
    "digit_outputs = []\n",
    "for ix, (data, labels) in enumerate(trn_dl):\n",
    "    mask = labels == digits[0]\n",
    "    if not mask.any():\n",
    "        continue\n",
    "    output = get_latent_batch(data[mask], model)\n",
    "    output = output.cpu().detach().numpy()\n",
    "    digit_outputs.append(output)\n",
    "digit_outputs = np.concatenate(digit_outputs, axis=0)\n",
    "mean_vector_0 = np.mean(digit_outputs, axis=0)\n",
    "\n",
    "digit_outputs = []\n",
    "for ix, (data, labels) in enumerate(trn_dl):\n",
    "    mask = labels == digits[8]\n",
    "    if not mask.any():\n",
    "        continue\n",
    "    output = get_latent_batch(data[mask], model)\n",
    "    output = output.cpu().detach().numpy()\n",
    "    digit_outputs.append(output)\n",
    "digit_outputs = np.concatenate(digit_outputs, axis=0)\n",
    "mean_vector_8 = np.mean(digit_outputs, axis=0)\n",
    "\n",
    "latent_vectors = torch.linspace(mean_vector_0, mean_vector_8, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_all_classes = np.mean(outputs, axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "im_tensor = torch.tensor(mean_all_classes).to(device)\n",
    "decoded = decode(im_tensor, model)\n",
    "ax.imshow(decoded[0].cpu().detach().numpy(), cmap='gray' )\n",
    "\n",
    "zeros_like_mean = torch.zeros_like(mean_all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors is the list of mean vectors for all classes\n",
    "# find pairwise distances between all mean vectors\n",
    "# use torch.norm to compute the norm of a vector\n",
    "# use torch.stack to create a tensor of shape (10, 10) from the 10 vectors\n",
    "# use plt.imshow to plot the \n",
    "from itertools import combinations\n",
    "\n",
    "pairs = list(combinations(range(10), 2)) \n",
    "vectors = torch.tensor(outputs)\n",
    "distances = torch.norm(vectors[:, None] - vectors[None, :], dim=2)\n",
    "# find classes with largest distance\n",
    "# use torch.argmax to find the index of the largest value in a tensor\n",
    "\n",
    "largest_distance = torch.argmax(distances)\n",
    "\n",
    "# find classes with smallest distance\n",
    "# use torch.argmin to find the index of the smallest value in a tensor\n",
    "\n",
    "print(f\"largest distance: {largest_distance}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
